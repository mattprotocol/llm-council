--- a/mcp_server/src/config/schema.py
+++ b/mcp_server/src/config/schema.py
@@ -50,6 +50,14 @@ class OpenAIProviderConfig(BaseModel):
     api_key: str | None = Field(default_factory=lambda: os.environ.get('OPENAI_API_KEY'))
 
 
+class OpenAIGenericProviderConfig(BaseModel):
+    """Configuration for OpenAI-compatible local LLM servers (LM Studio, Ollama, etc.)."""
+    
+    api_key: str | None = Field(default='not-needed', description='API key (usually not required for local servers)')
+    api_url: str = Field(
+        default_factory=lambda: os.environ.get('OPENAI_BASE_URL', 'http://localhost:1234/v1'),
+        description='Base URL for the OpenAI-compatible API'
+    )
+
+
 class AzureOpenAIProviderConfig(BaseModel):
     """Configuration for Azure OpenAI provider."""
     
@@ -120,6 +128,7 @@ class LLMProviders(BaseModel):
     """Configuration for available LLM providers."""
     
     openai: OpenAIProviderConfig | None = Field(default_factory=OpenAIProviderConfig)
+    openai_generic: OpenAIGenericProviderConfig | None = Field(default_factory=OpenAIGenericProviderConfig)
     azure_openai: AzureOpenAIProviderConfig | None = None
     anthropic: AnthropicProviderConfig | None = None
     gemini: GeminiProviderConfig | None = None
